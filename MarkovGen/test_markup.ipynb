{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we will show the model performance against the test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Markov Text Generator.\n",
    "\n",
    "Patrick Wang, 2023\n",
    "\n",
    "Resources:\n",
    "Jelinek 1985 \"Markov Source Modeling of Text Generation\"\n",
    "\"\"\"\n",
    "\n",
    "import nltk\n",
    "\n",
    "from mtg import finish_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['she' 'was' 'not' 'in' 'the' 'world' '.']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test Markov text generator.\"\"\"\n",
    "corpus = nltk.word_tokenize(nltk.corpus.gutenberg.raw(\"austen-sense.txt\").lower())\n",
    "\n",
    "words = finish_sentence(\n",
    "    [\"she\", \"was\", \"not\"],\n",
    "    3,\n",
    "    corpus,\n",
    "    randomize=False,\n",
    ")\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['robot' ',' 'and' 'the' 'two' 'miss' 'steeles' ',' 'as' 'she']\n"
     ]
    }
   ],
   "source": [
    "words2 = finish_sentence(\n",
    "    [\"robot\"],\n",
    "    3,\n",
    "    corpus,\n",
    "    randomize=False,\n",
    ")\n",
    "print(words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['she' 'was' 'not' ',' ',' ',' ',' ',' ',' ',']\n"
     ]
    }
   ],
   "source": [
    "words3 = finish_sentence(\n",
    "    [\"she\", \"was\", \"not\"],\n",
    "    1,\n",
    "    corpus,\n",
    "    randomize=False,\n",
    ")\n",
    "print(words3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['robot' ',' 'and' 'the' 'same' 'time' ',' 'and' 'the' 'same']\n"
     ]
    }
   ],
   "source": [
    "words4 = finish_sentence(\n",
    "    [\"robot\"],\n",
    "    2,\n",
    "    corpus,\n",
    "    randomize=False,\n",
    ")\n",
    "print(words4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next we will look at the random case. We will use a larger n because it produces more interesting sentences and see that for the same initial parameters, different sentences are selected: (we will start with a deterministic pass to see the output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['she' 'was' 'not' 'in' 'the' 'house' ',' 'and' 'they' 'were']\n"
     ]
    }
   ],
   "source": [
    "words5_5 = finish_sentence(\n",
    "    [\"she\", \"was\", \"not\"],\n",
    "    4,\n",
    "    corpus,\n",
    "    randomize=False,\n",
    ")\n",
    "print(words5_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now the ouputs from randomly selected candidate words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['she' 'was' 'not' 'suspected' 'of' 'any' 'extraordinary' 'interest' 'in'\n",
      " 'it']\n"
     ]
    }
   ],
   "source": [
    "words5 = finish_sentence(\n",
    "    [\"she\", \"was\", \"not\"],\n",
    "    4,\n",
    "    corpus,\n",
    "    randomize=True,\n",
    ")\n",
    "print(words5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['she' 'was' 'not' 'aware' 'that' 'such' 'language' 'could' 'be'\n",
      " 'suffered']\n"
     ]
    }
   ],
   "source": [
    "words6 = finish_sentence(\n",
    "    [\"she\", \"was\", \"not\"],\n",
    "    4,\n",
    "    corpus,\n",
    "    randomize=True,\n",
    ")\n",
    "print(words6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The above is actually a completely legible sentence which is interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['she' 'was' 'not' 'doomed' ',' 'however' ',' 'to' 'be' 'sure']\n"
     ]
    }
   ],
   "source": [
    "words7 = finish_sentence(\n",
    "    [\"she\", \"was\", \"not\"],\n",
    "    4,\n",
    "    corpus,\n",
    "    randomize=True,\n",
    ")\n",
    "print(words7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That is the conclusion of this markov text generator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
